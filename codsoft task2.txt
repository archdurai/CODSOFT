import pandas as pd
import numpy as np
import plotly.express as px
import sklearn as sk
import seaborn as sns
import matplotlib.pyplot as plt
data = pd.read_csv(r"C:\Users\archu\Downloads\archive (1)\IMDb Movies India.csv", encoding='unicode_escape')
print(data.duplicated().sum())
print(data.dropna(inplace=True))
print(data.info())
print(data.shape)
print(data.isnull().sum())
print(data.drop_duplicates(inplace=True))
print(data.columns)
data['Year']=data['Year'].str.replace(r'[()]','',regex=True).astype(int)
print(data['Year'].head(10))
data['Duration']=pd.to_numeric(data['Duration'].str.replace(' min',''))
print(data['Duration'].head())
data['Genre']=data['Genre'].str.split(',')
data=data.explode('Genre')
data['Genre'] = data['Genre'].fillna(data['Genre'].mode()[0])
data['Votes'] = pd.to_numeric(data['Votes'].str.replace(',', ''))
print(data.info())
year=px.histogram(data,x='Year',histnorm='probability density',nbins=30)
year.show()
avg = data.groupby(['Year', 'Genre'])['Rating'].mean().reset_index()
top = data['Genre'].value_counts().head(10).index
avg=avg[avg['Genre'].isin(top)]
fig=px.line(avg,x='Year',y='Rating',color='Genre')
fig.update_layout(title='Average Rating',xaxis_title = 'Year',yaxis_title = 'Average Rating')
fig.show()
ratingf=px.histogram(data,x='Rating',histnorm='probability density',nbins=40)
ratingf.update_layout(title='Distribution of Rating',title_x=0.5,title_pad=dict(t=20),title_font=dict(size=20),xaxis_title = 'Rating',yaxis_title = 'Probability of Rating')
ratingf.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.impute import SimpleImputer
from sklearn.pipeline import make_pipeline

# Load your dataset
data = pd.read_csv(r"C:\Users\archu\Downloads\archive (1)\IMDb Movies India.csv", encoding='unicode_escape')  # Replace with your actual file path

# Clean 'Votes': remove commas and convert to float
data['Votes'] = data['Votes'].astype(str).str.replace(',', '').str.strip()
data['Votes'] = pd.to_numeric(data['Votes'], errors='coerce')

# Clean 'Year': extract only year digits and convert to int
data['Year'] = data['Year'].astype(str).str.extract(r'(\d{4})')
data['Year'] = pd.to_numeric(data['Year'], errors='coerce')

# Clean 'Duration': remove 'min' and convert to float
data['Duration'] = data['Duration'].astype(str).str.replace('min', '').str.strip()
data['Duration'] = pd.to_numeric(data['Duration'], errors='coerce')
# Drop rows with missing values in key columns (Year, Votes, Duration, Rating)
data = data.dropna(subset=['Year', 'Votes', 'Duration', 'Rating'])

# Encode genres, directors, actors using mean rating
data.drop('Name', axis=1, inplace=True)

gmr = data.groupby('Genre')['Rating'].transform('mean')
data['gmr'] = gmr

dmr = data.groupby('Director')['Rating'].transform('mean')
data['director_encoded'] = dmr  # Ensure column name is consistent

data.rename(columns={'Actor 1': 'Actor1', 'Actor 2': 'Actor2', 'Actor 3': 'Actor3'}, inplace=True)

a1mr = data.groupby('Actor1')['Rating'].transform('mean')
data['actor1'] = a1mr

a2mr = data.groupby('Actor2')['Rating'].transform('mean')
data['actor2'] = a2mr

a3mr = data.groupby('Actor3')['Rating'].transform('mean')
data['actor3'] = a3mr

# Prepare features and target
X = data[['Year', 'Votes', 'Duration', 'gmr', 'director_encoded', 'actor1', 'actor2', 'actor3']]
y = data['Rating']

# Check if there are any trailing spaces in the column names
X.columns = X.columns.str.strip()  # Remove any leading/trailing spaces from column names

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Ensure the column names in X_train and X_test are the same
X_train.columns = X.columns  # Align columns between training and testing data
X_test.columns = X.columns

# Create a pipeline that first imputes missing values and then fits the model
model = make_pipeline(SimpleImputer(strategy='mean'), LinearRegression())

# Train the model
model.fit(X_train, y_train)

# Predict the values
model_pred = model.predict(X_test)

# Evaluation
print('Performance of Linear Regression:')
print('Mean Squared Error:', mean_squared_error(y_test, model_pred))
print('Mean Absolute Error:', mean_absolute_error(y_test, model_pred))
print('R2 Score:', r2_score(y_test, model_pred))


print(X.head())
print(y.head())

data={'Year':[2019],'Votes':[36],'Duration':[111],'gmr':[5.8],'director_encoded':[4.5],'actor1':[5.3],'actor2':[4.5],'actor3':[4.5]}
trail=pd.DataFrame(data)
ratped=model.predict(trail)
print("Predicted rating:",ratped[0])
